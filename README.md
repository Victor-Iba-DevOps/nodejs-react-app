                                    React application CI\CD Jenkins pipeline.


Структура и порядок имплементации конвейера следующие:

*   В рабочую директорию локальной машины командой \
 `gh repo clone Victor-Iba-DevOps/nodejs-react-app` \
клонируется репозиторий с файлами исходного кода React-приложения и файлами, необходимыми для реализации конвейера. Переходим в директорию *Jenkins*, проверяем, что у файлов скриптов есть нужные права на исполнение командой \
 `stat -c %a codechange.sh codechangeback.sh` \
выводимый терминалом результат для них должен быть *775*, если же нет -- делаем файлы исполняемыми актуальным пользователем командой \
 `sudo chmod u+x codechange.sh codechangeback.sh`
   
*   На локальной машине устанавливается Docker, и с его помощью посредством команды \
`docker build -f Dockerfile_agent -t react-agent .` \
создается образ агента *react-agent* для сборки React-приложений. Для этого, согласно Докерфайлу [Dockerfile_agent](https://github.com/Victor-Iba-DevOps/nodejs-react-app/blob/main/Dockerfile_agent), за основу с репозитория *Dockerhub* берется дефолтный образ для агентов Jenkins, подключаемых по протоколу SSH, -- [jenkins/ssh-agent:jdk11](https://hub.docker.com/r/jenkins/ssh-agent), на котором уже добавлен user *Jenkins* с UID/GID=1000, Java runtime, SSH-agent, а далее с root правами на него добавляются необходимые утилиты и сертификаты, устанавливаются Docker Engine + cli, Node, npm, их успешная установка в образ проверяется при помощи команды \
`--version` \
затем user Jenkins добавляется в группу пользователей, имеющих право управлять Docker, а GID самого докера внутри агента меняется на соответствующий GID Docker на локальной машине -- 980 (конкретный частный случай, для уточнения этого числа необходимо на локальной машине ввести нижеследующую команду) \
`getent group docker | cut -d ':' -f 3` \
В результате этой операции получаем готовый образ агента *react-agent:latest*;

*   Для автоматизации запуска конвейера можно выбрать варианты периодического включения с предопределенным промежутком времени, периодического опроса репозитория на предмет обновления исходного кода, либо же настроить связь репозитория с Jenkins-клиентом посредством webhook, что позволит строить и обновлять развернутое приложение только после обновления исходного кода, что исключит overhead траффика запросов на репозиторий и повысит экономию серверных ресурсов. 
Так как локальная машина находится за фаерволом, нужно открыть в нем порт, чтобы к Jenkins поступали сигналы из репозитория. Для того, чтобы не компрометировать этим локальную сеть (либо в условиях отсутствия доступа к администрированию фаервола) можно воспользоваться webhook proxy утилитой [smee.io](https://smee.io/), которая устанавливается на локальную машину или же запускается в контейнере параллельно с самим Jenkins (в данном примере реализован второй вариант). В браузере открывается [новый канал](https://smee.io/new), где сайт автоматически присвоит и выдаст *url*, который можно использовать в файлах конфигурации и настройках, поэтому его нужно сохранить. В конкретно данном случае используется proxy адрес [smee.io/iMncubqOnirnb8yO](https://smee.io/iMncubqOnirnb8yO);

*   Для имитации развертывания построенного приложения в облачном кластере Kubernetes воспользуемся [Minikube](https://minikube.sigs.k8s.io/docs/). После установки на локальную машину запускаем его командой \
`minikube start --driver=docker` \
Minikube при запуске создаст для своих нужд docker сеть *minikube*, затем для определения его ip-адреса в этой сети можно воспользоваться командой \
`docker container inspect minikube | grep IPv4Address` \
или же обратиться с запросом к самому Minikube командой \
`minikube ip` \
он по умолчанию занимает первый доступный адрес *192.168.х.2* (в данном случае это был *192.168.49.2*)

*   Для того, чтобы Jenkins-контроллер мог связываться с кластером *Kubernetes* и управлять процессом развертывания приложения в нём, они должны друг друга видеть, обычно это подключение реализуется по протоколу ssh по реальными ip-адресам, но если они оба развернуты в docker-контейнерах на локальной машине, то можно воспользоваться возможностями *Docker* и объединить их в общей сети, которую создаёт *Minikube* при запуске. Для этого в файле [docker-compose.yml](https://github.com/Victor-Iba-DevOps/nodejs-react-app/blob/main/docker-compose.yml) для всех запускаемых контейнеров указывается уже существующая сеть *minikube*.  

*   Далее командой \
`docker-compose up -d` \
(флаг `-d` определяет то, что контейнеры будут запущены в фоновом режиме, не блокируя активный терминал) запускаются три контейнера *Jenkins*, *Agent* и *Proxy* согласно файлу [docker-compose.yml](https://github.com/Victor-Iba-DevOps/nodejs-react-app/blob/main/docker-compose.yml), в котором прописан следующее:
1. контейнер *"Jenkins"* будет запущен из дефолтного образа Jenkins с Dockerhub [jenkins/jenkins:lts-jdk11](https://hub.docker.com/r/jenkins/jenkins), ему будет присвоено имя "jenkins", на его порт 8080 будет проброшен соответствующий порт 8080 локальной машины для доступа из браузера, и на порт 50000 будет проброшен соответствующий порт 50000 для управления slave-агентами и slave-pod kubernetes кластера, для сохранения данных (пароль администратора, плагины, настройки, построенные конвейеры и логи их работы и так далее) к домашней директории `/var/jenkins_home/` контейнера создается и подключается статический *Docker volume*, названный "jenkins";
2. контейнер *"Agent"* будет запускаться из созданного ранее образа `react-agent:latest`,ему присваивается имя "agent", он будет запускаться после старта контейнера "jenkins", он будет "слушать" внешние подключения по протоколу SSH по 22му порту, для сохранения необходимой информации (авторизованный ssh-ключ, файлы конфигураций и файл подключения Jenkins-контроллера) ему к директории `/home/jenkins/` будет создан и подключен статичный *Docker volume*, названный "react-node", а для управления Docker daemon локальной машины Docker'ом контейнера он будет подключен к нему через *Unix socket* (`/var/run/docker.sock:/var/run/docker.sock`) (Такая "подмена" необходима из-за того, что попытки создавать новые образы в контейнеризованном приложении с установленным внутри этого контейнера Docker в привилегированном режиме с root-правами могут создавать [конфликты и угрозы безопасности](https://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/), а методом подключения через Docker socket мы симулируем агент с установленным на нём Docker, где ход выполнения конвейера будет аналогичным удалённому серверу или виртуальной машине);
3. контейнер *"Proxy"* будет запускаться из образа [deltaprojects/smee-client:latest](https://hub.docker.com/r/deltaprojects/smee-client), ему будет присвоено имя "smee", при запуске ему будут указаны для выполнения команды `-u https://smee.io/iMncubqOnirnb8yO` (сюда нужно вставить адрес, который был получен выше при создании нового канала smee, это адрес, на который будут поступать push-уведомления с репозитория и который smee-клиент будет опрашивать для их получения) и `-t http://192.168.49.3:8080/project/node-react-app` (это адрес конвейера в Jenkins -- после проброса с localhost -- на который smee-клиент будет передавать push-уведомления). \
   Все контейнеры будут подключены к уже существующей сети *minikube* и автоматически перезапущены при рестарте машины или любых других условиях, кроме их остановки вручную командой \
`docker container stop jenkins\agent\proxy` \
То, что благодаря ключу *depends_on* контейнеры Agent и Smee запускаются только после контейнера Jenkins, гарантирует то, что Jenkins займёт первый доступный из ip-адресов сети, которым является 192.168.49.3 (192.168.49.1 - адрес network Gateway, 192.168.49.2 - адрес Minikube), и эта фиксация позволяет использовать его в настройках напрямую, без переменных.
Со временем Docker-образы Jenkins и Smee на репозитории могут обновляться, и чтобы использовать новые версии, нужно будет остановить и отключить их командой \
`docker compose down` \
Затем удалить старые образы командой \
`docker rmi jenkins/jenkins:lts-jdk11 deltaprojects/smee-client:latest` \
и заново запустить командой \
`docker-compose up -d` 

*   Для создания ssh ключа на агенте, который будет в этой паре выполнять фунцкию ssh-server, заходим в контейнер под пользователем *jenkins* командой \
`docker exec  -it --user jenkins agent bash` \
проверяем, что мы находимся в home directory пользователя *jenkins* командой \
`pwd` \
(выводимый на экран результат должен быть `/home/jenkins`, если он отличается, то можно проверить пользователя командой `whoami`, он должен быть *jenkins*), здесь создаем скрытую папку `.ssh` и в ней создаем пару ssh-ключей командой \
`mkdir ~/.ssh && cd ~/.ssh/ && ssh-keygen -t rsa -f "jenkins_agent_key"` \
добавляем публичный ключ в список авторизованных для подключения командой \
`cat jenkins_agent_key.pub >> ~/.ssh/authorized_keys` \
устанавливаем необходимые уровни доступа к директории и ключам командой \
`chmod 700 ~/.ssh && chmod 600 ~/.ssh/authorized_keys ~/.ssh/jenkins_agent_key` \
Выводим на экран содержимое приватного и публичного ключей командами \
`cat ~/.ssh/jenkins_agent_key` \
`cat ~/.ssh/jenkins_agent_key.pub` \
копируем их в отдельные временные файлы на локальной машине для настройки подключения Jenkins чуть позже и выходим из контейнера командой \
`exit`

*   Далее в браузере локальной машины заходим по адресу [localhost:8080](localhost:8080) в графическую оболочку *Jenkins*, и так как это его первый запуск, Jenkins запросит автоматически сгенерированный пароль, сохраненный в его логах запуска (и продублированный в отдельном файле), воспользуемся командой \
`docker logs jenkins` \
чтобы его найти и скопировать для разблокирования -- он будет между двух тройных рядов звёздочек в логе. Альтернативно, можем войти в контейнер командой \
`docker exec -it jenkins bash` \
и вывести пароль в терминал командой \
`cat /var/jenkins_home/secrets/initialAdminPassword` \
Далее Jenkins предложит установить плагины по умолчанию и создать учетную запись администратора, после чего заходим в меню \
-"*Manage jenkins > Configure system*" и в поле "*# of executors"* меняем значение на `0`, для того, чтобы все задачи выполнялись не контроллером, а агентами; \
-в поле *Labels* указываем *jenkins*, \
-в поле *Usage* -- *only build jobs with label expressions matching this node*, \
-в поле *Jenkins URL* указываем адрес http://192.168.49.3:8080/, по нему впоследствии из браузера можно будет открыть интерфейс Jenkins, \
-Проверяем установленные по умолчанию плагины и добавляем при необходимости следующие: \
*Credentials + Credentials Binding, Docker Pipeline, Docker, Pipeline: Basic Steps,  Pipeline: Declarative, Git, Generic Webhook Trigger, SSH Build Agents, SSH Credentials, Kubernetes, Kubernetes CLI, Kubernetes Continuous Deploy,Workspace Cleanup* и их зависимости;

*   Для подключения агента открываем меню \
-*Manage Jenkins > Manage Nodes and Clouds > New Node*, \
-называем наш агент к примеру "*React-builder*", выбираем для него опцию "*Permanent type*", \
-затем в меню конфигурации ставим `1` в поле "*Number of executors*" (в правилах хорошего тона выставляется в зависимости от количества доступных процессорных ядер или потоков виртуальной машины, в этом случае есть только один линейный конвейер, поэтому можно оставить 1), \
-в поле "*Remote root directory*" пишем адрес домашней директории пользователя jenkins `/home/jenkins` (в ней у него будут права для создания, чтения и изменения файлов для копирования remoting.jar и управления через него агентом), \
-в поле "*Labels*" -- `react` (для указания в декларативной части, что этот конвейер должен исполнять именно этот агент), \
-в поле "*Usage*" -- что исполнять агент будет только те этапы и те конвейеры, в которых это непосредственно указано, \
-в поле "*Launch method*" -- запуск посредством протокола ssh: в поле "*Host*" указываем имя контейнера `agent` (либо его адрес во внутренней сети, которую организовывает docker при запуске через docker-compose, его можно проверить, выполнив команду \
`docker inspect agent` \
но он может варьироваться после перезапуска контейнера, если не позаботиться о его постоянстве при помощи файла docker-compose), \
-в поле "*Credentials*" нажимаем "add", чтобы добавить ключ для подключения: *Global > SSH Username with private key > Global > ID (оставить поле пустым) >  Description = react agent ssh key > Username = jenkins > Private key = ставим галочку на "enter key directly" и вставляем в поле ключ, который взяли из `~/.ssh/jenkins_agent_key` в контейнере агента и сохранили в отдельном временном файле > сохраняем и добавляем ключ Credentials*, \
-в поле "*Host Key Verification Strategy*" выбираем "Manually provided key verification strategy" и в поле "*SSH Key*" вставляем ключ, который скопировали из `~/.ssh/jenkins_agent_key.pub` контейнера агента, \
-в поле "*Availability*" выбираем "*Bring this agent online when in demand and take him offline when idle*" (для удобства во время тестирования конвейера можно оставить агент всегда онлайн, но для практики экономии ресурсов агенты должны находиться по умолчанию в спящем режиме, активироваться только по требованию контроллера для выполнения конкретных задач и обратно выключаться). \
Сохраняем выбранные настройки, нажимаем "*Launch agent*" и открываем лог подключения, он должен заканчиваться строкой
> *Agent successfully connected and online*

*   Для того, чтобы Jenkins мог подключаться к кластеру Minikube, это необходимо сконфигурировать: \
По адресу `~/.kube/config` на локальной машине лежит файл конфигурации Kubernetes кластера Minikube, но в таком виде использовать его в качестве Credentials не выйдет, поскольку в нем используются ссылки на файлы сертификатов, которые так же находятся на локальной машине, но которых не будет в контейере Jenkins, когда он будет производить попытку подключения. \
Это можно было бы обойти копированием в соответствующие директории в контейнере Jenkins и подключением статических хранилищ Docker-volume для них, но это излишне усложняет файл конфигурации docker-compose. В качестве альтернативы можно изменить данный файл, чтобы в нём вместо ссылок на сертификаты были непосредственно закодированные данные самих сертификатов. \
Для этого копируем файл командой \
`cp ~/.kube/config ~/.kube/jenkins_config` \
-заходим в созданную копию, меняем *certificate-authority* на *certificate-authority-data* \
-перекодируем содержимое сертификата в нужный формат командой \
`cat ~/.minikube/ca.crt | base64 -w 0; echo` \
-и вставляем выведенный в терминале ключ вместо ссылки на него (~/.minikube.ca.crt). \
-проводим аналогичные операции с ключами `client-certificate` и `client-key` и сохраняем файл конфигурации.
Далее заходим в настройки Jenkins: \
-*Manage Jenkins > Manage nodes and clouds > Configure Clouds > add new cloud > Kubernetes* \
-указываем имя *kubernetes*, \
-нажимаем *Kubernetes cloud details*, \
-называем *Kubernetes Namespace* *jenkins*, \
-добавляем в качестве Credentials измененный файл конфигурации jenkins_config (add > secret file > присваиваем ему ID на выбор), \
-нажимаем *Test connection*, чтобы проверить подключение Jenkins к кластеру Minikube, должна появиться надпись \
*Connected to Kubernetes v1.х* \
-в Jenkins URL указываем адрес [http://192.168.49.3:8080/](http://192.168.49.3:8080/), \
-Pod Labels можно назвать на свое усмотрение или оставить значения по умолчанию, \
-нажимаем кнопку *Pod templates* и называем шаблон по своему усмотрению, \
-нажимаем кнопку *Pod template details* и заполняем следующие поля: \
-*Namespace*: *jenkins* \
-*Labels*: *kubernetes* \
-*Usage*: *use this node as much as possible* \
-нажимаем *add container* и заполняем следующие поля: \
-*Docker image*: *jenkins/inbound-agent* \
-*Working directory*: */home/jenkins/agent* \
-остальные поля оставить с предустановленными значениями и сохранить конфигурацию;

*   Для того, чтобы в ходе выполения конвейера Jenkins-контроллер мог при помощи плагина Kubernetes Continuous Deploy передать файл конфигурации в Minikube Api, ему нужно создать ключ Credentials:
-заходим в *Manage Jenkins > Security > Manage Credentials*, \
-в таблице "*Stores scoped to Jenkins*" нажимаем на "*global*", \
на новой странице нажимаем "*Add Credentials*" и выбираем тип *Kind = Kubernetes configuration(kubeconfig)*, \
-в поле *ID* присваиваем ему имя по усмотрению, например *kubernetesConfig*, \
-выбираем *enter directly* в следующем меню и копируем в окошко содержимое измененного файла конфигурации \
`~/.kube/jenkins_config` и сохраняем созданный Credentials.

*   Для того, чтобы собранные конвейером образы приложения могли быть залиты на удаленный репозиторий в ходе выполнения конвейера, нужно внести реквизиты учетной записи в Jenkins. В данном случае я воспользовался открытым репозиторием [Dockerhub](https://hub.docker.com/repository/docker/victoribatraineedevops/training-repo). \
Заходим в меню *Manage Jenkins > Security > Manage Credentials*, \
в таблице "*Stores scoped to Jenkins*" нажимаем на "*global*", \
на новой странице нажимаем "*Add Credentials*": \
*Kind = Username with password, Scope = Global, Username = Dockerhub_username, Password = Dockerhub_password, ID = DockerhubID (можно назвать как удобно)*, сохраняем реквизиты;

*   Согласно файлу [reactapp.yml](https://github.com/Victor-Iba-DevOps/nodejs-react-app/blob/main/docker-compose.yml), в kubernetes кластере разворачивается ingress на адрес **reactapp.com**, и для того, чтобы этот адрес корректно отображался в браузере на локальной машине, нужно перенаправить его на адрес minikube, поэтому проверяем ip-адрес minikube командой \
`minikube ip` \
в данном случае он был *192.168.49.2*, далее командой \
`sudo vim /etc/hosts` \
редактируем Loopback entries и добавляем в них строку 
`192.168.49.2 reactapp.com` \
Это позволит обращаться через созданный в minikube ingress к развернутым там pod'ам с React-приложением без ip-адреса, а по такому адресу. 

*   Теперь можно приступать к созданию конвейера в Jenkins: \
-*Jenkins dashboard > New Item > Multibranch Pipeline*, выбираем имя для конвейера (в данном случае я назвал его *node-react-app*), \
-в настройках конвейера ставим галочки в полях "GitHub project" (добавляем cюда [url репозитория](https://github.com/Victor-Iba-DevOps/nodejs-react-app), и далее в следующих полях: \
-"*GitHub hook trigger for GITScm polling*" (для автоматической активации конвейера каждый раз, когда на репозитории обновляется или добавляется код), \
-в *Definition* выбираем из выпадающего меню "*Pipeline script from SCM*", \
-в *SCM* -- "*Git*", \
-в *Repository url* добавляем [url репозитория](https://github.com/Victor-Iba-DevOps/nodejs-react-app) \
-в *Branch specifier* указываем ветку (по умолчанию это *master*, можно добавить *dev*, *feature*, и т.д.), \
-а в поле *Script path* указываем `Jenkinsfile` без уточнений, поскольку он лежит в корневой директории репозитория. \
Сохраняем настройки конвейера;

*   Пройдемся по порядку по заданным в Jenkinsfile командам: 

1.  В Environment объявлены переменная *credentials*, которая берет данные при обращении к ней из *'DockerhubID' credentials*, и переменная *Image*.
2.  В options установлен параметр *skipStagesAfterUnstable*, который остановит выполнение конвейера, если на какой-либо из его стадий произойдет ошибка исполнения или неожиданное событие.
3.  Исполняющим агентом конвейера назначены агенты с меткой *'react'*, и так как такой у нас один, то выполнять поставленные задачи будет выполнять именно он, а не контроллер или какие-либо другие агенты, кроме стадии *Deploy*, в которой назначен отдельный агент.
4. Так как конвейер задан в декларативной форме, первоначально Jenkins выполняет стадию *Declarative: Checkout SCM*, в которой он устанавливает при помощи credentials соединение с репозиторием и копирует себе его содержимое,  
5.  На стадии *Install* команда `npm install` устанавливает в рабочую директорию *~/workspace/nodejs-react-app/node_modules/* React приложение из директории *./src* и все необходимые зависимости для построения данного приложения, перечисленные в файле *package.json*.
6.  На стадии *Test* командой `npm test` вызывается фреймворк для тестирования приложений *Jest*, который проверяет, корректно ли отрисовывается установленное React приложение.
7.  На стадии *Build* командой `npm run build` из файлов установленного приложения создается оптимизированный для развертывания на веб-сервере билд приложения со всеми необходимыми для этого файлами и они помещаются в директорию *./build*.
8.  На стадии *Push* сперва запускается скрипт (так как декларативный метод построения конвейера не позволяет напрямую задавать подобные команды, то они используюся в блоке *script{}* ), в котором переменной *Image* присваивается результат команды `docker.build("victoribatraineedevops/training-repo:1.${env.BUILD_ID}")` , в которой указывается, что *tag* собираемого образа будет соответствовать репозиторию, на который он будет впоследствии загружаться, с текущим порядковым номером билда *Jenkins-конвейера* для легкой идентификации в дальнейшем, а сборка образа будет проходит согласно *[Dockerfile](https://github.com/Victor-Iba-DevOps/nodejs-react-app/blob/main/Dockerfile)* (так как в команде отдельно не указан другой *dockerfile*), находящемуся в корне репозитория GitHub. \
В *[Dockerfile](https://github.com/Victor-Iba-DevOps/nodejs-react-app/blob/main/Dockerfile)* указано, что за основу берется образ [nginx:stable-alpine](https://hub.docker.com/layers/nginx/library/nginx/stable-alpine/images/sha256-72defb0353f4fb7a3869a2b89d92fbc3b6a99b48d1b960bba092fa3c8d093eed) c *Dockerhub* (минимального размера веб-сервер для развертывания приложения) и в его директорию */usr/share/nginx/html* копируются файлы билда *React* приложения из директории *build/* нашего агента. \
Затем командой `docker.withRegistry('', credentials)` инициализуется процесс логина в репозиторий *Dockerhub* (а так как не указан адрес какого-то другого репозитория, *Dockerhub* используется по умолчанию) под именем и паролем, указанным в *DockerhubID credentials*, \
после авторизации командой `Image.push()` содержимое переменной *Image* -- а это построенный Docker образ веб-сервера nginx с React приложением -- загружается в удаленный репозиторий. \
Командой `Image.push 'latest'` этому же образу переназначается тег latest и с ним образ тоже загружается в репозиторий, заменяя там предыдущий образ с аналогичным именем. \
Далее командой `sh 'docker logout'` производится разлогинивание из *Dockerhub* и удаление реквизитов из временного файла в агенте, и \
командой `sh "docker rmi nginx:stable-alpine victoribatraineedevops/training-repo:1.${env.BUILD_ID} victoribatraineedevops/training-repo:latest"` удаляются из реестра и устройств хранения на агенте (в данном случае *docker daemon* агента подключен к докеру на локалхосте, который выполняет все эти и следующие команды и хранит образы, но в общем принципе агентом должен служить удаленный сервер или виртуальная машина) скачанный в этой стадии образ nginx и созданный образ веб-сервера с установленным приложением под обоими присвоенными ему тегами. Это делается для экономии места на устройствах хранения и возвращения рабочей среды в состояние, идентичное состоянию до начала работы конвейера.

9.   На стадии *Deploy* исполняющим агентом (через функцию `inheritFrom 'kubernetes'`) kubernetes-кластером назначается созданный в этот момент master-pod с рандомным именем (начинающимся на `pod template name` из конфигурации Jenkins kubernetes cloud), \
в который копируются исходные файлы с репозитория, включая [reactapp.yml](https://github.com/Victor-Iba-DevOps/nodejs-react-app/blob/feature/reactapp.yml), \
который редактируется в нем (и только в нём, без изменения в репозитории либо где-либо ещё) командой \
`sh 'sed -i "s/latest/1.${BUILD_NUMBER}/" reactapp.yml'` \
которая позволяет заменить в статичном файле конфигурации развертывания тег *latest* на тег, соответствующий порядкововому номеру билда конвейера. Образы с этими тегами в данный момент времени идентичны, так как были созданы и загружены в репозиторий несколькими секундами ранее. \
Это делается для того, чтобы хранить на репозитории и использовать статичный файл конфигурации, но отправлять в kubernetes-кластер на обновление развертывания уже обновленный файл, который будет отличаться от предыдущего и триггерить изменение deploy'я. Данные текущей конфигурации можно проверить командой \
`kubectl describe deployment reactapp-deploy --namespace jenkins | grep Image` \
где будет указан порядковый номер в теге образа, использованного в последнем обновлении развертывания. \
Затем при помощи плагина *Kubernetes Continuous Deploy* с данными конфигурации из ранее созданных *credentials* *kubernetesConfig* командой \
`kubernetesDeploy(configs: "reactapp.yml", kubeconfigId: "kubernetesConfig")` \
в kubernetes-кластер подается для развертывания (или обновления, если он там уже присутствует) файл конфигурации [reactapp.yml](https://github.com/Victor-Iba-DevOps/nodejs-react-app/blob/feature/reactapp.yml). \
Если это первое развертывание, то кластер создаст все элементы, согласно файлу конфигурации, включая pod'ы с веб-сервером, \
если же нет, то он триггерит обновление Replica set, и по очереди будет создавать новые pod'ы с контейнерами из нового образа и синхронно с этим по очереди отключать pod'ы со старыми, и через несколько секунд активными останутся только новые.
Этот подход (Rollout Deployment Strategy) позволяет оставлять доступной старую версию приложения (если Replica Set был >1, разумеется), пока создаются pod'ы с новой, и Ingress как Load balancer перенаправляет на них запросы, поступающие на кластер, позволяя избежать downtime и недоступность ресурса во время обновления версий.

10.  Последней стадией *post* при любом результате окончания выполнения конвейера, будь это успешное развертывание приложения или аварийная остановка из-за ошибки на какой-либо из его стадий, проходит удаление командой `cleanWs()` всей информации , хранящейся в рабочей директории *~/workspace* агента, в частности файлы исходных кодов, которые безусловно должны загружаться заново при каждом изменении на репозитории, чтобы не допускать конфликтов версий и гарантированно каждый раз строить новые версии приложения из нового кода.

*  Подготовительные шаги завершены, можем запускать наш конвейер, на первый раз вручную, чтобы протестировать все элементы, просмотреть лог вывода консоли и сравнить его с ожидаемыми результатами. \
Выбираем на *dashboard* конвейер, в меню слева нажимаем "*Build Now*", \
снизу в меню "*Build History*" появится новая строка "*#{build_number}*" (в этом случае это будет #1), нажимаем на нее, \
и в новом окне слева выбираем "*Console Output*", который в режиме реального времени будет отображать текущие операции конвейера и их результат. \
Если все необходимые условия были соблюдены, то все стадии должны пройти успешно, в конце *Console Output Log* будет строка 
> **Finished: SUCCESS** 

и по адресу [http://reactapp.com](http://reactapp.com) нас приветствует развернутое React приложение.

*  Для демонстрации автоматической работы всей цепочки по сборке приложения по триггеру webhook при каждом обновлении кода на *GitHub* репозитории в терминале на локальной машине находясь в рабочей директории клонированного репозитория jenkins запускаем скрипт командой `./codechange.sh`, который заменяет исходный код приложения на слегка измененную версию из папки "*srcnew*" и отправляет новый коммит на *GitHub* , тем самым запуская всю цепочку выполнения конвейера снова, уже с новым кодом, после выполнения которой (в том числе и обновления kubernetes pods, что займёт несколько минут) нужно обновить страницу в браузере, чтобы увидеть новую версию React приложения. В репозитории для удобства добавлен скрипт `./codechangeback.sh`, который возвращает код в исходное состояние и опять же push'ит его на GitHub, запуская снова Jenkins конвейер и развертывание старой версии приложения. 

                                  Способ обновления без изменения файлов развертывания.

*  На стадии *Deploy* после изначального развертывания приложения в кластере для внесения изменений можно применять команды `kubectl patch` вместо изменения файлов deployment'а, к примеру: \
`kubectl patch deployment reactapp-deploy --namespace jenkins --type='merge' -p '{"spec": {"replicas":8}}'` \
для изменения количества активных pod'ов, (после исполнения команды конвейером на этой стадии deployment и все его остальные параметры останутся прежними, а параметру ReplicaSet присвоится значение *8* и соответственно будут созданы 4 новых pod'а), или же \
`kubectl patch deployment reactapp-deploy --namespace jenkins --type='merge' --patch '{"spec": {"template": {"spec": {"containers": [{"name": "reactapp","image": "victoribatraineedevops/training-repo:1.356"}]}}}}'` \
для проверки конкретной версии образа приложения (старые pod'ы будут планомерно отключаться по одному одновременно с созданием новых по образу, указанному в команде).
   
                                  Альтернативный вариант развертывания приложения на базе Docker локальной машины:

*  Стадия *Deploy* Дженкинс-конвейера и описание принципа ее работы:
```
  stage('Deploy') {
         steps {
            script {
               try {
                  sh 'docker stop reactapp && docker rm reactapp'
                  echo 'Previously deployed application is removed, proceeding with the deployment of new version.'
               }
               catch (err) {
                  echo 'No previously deployed applications were detected, proceeding with the deployment of new version.'
                  currentBuild.result = 'SUCCESS'
               }
            }
            script {
               try {
                  sh "docker rmi -f \$(docker images -a -q 'victoribatraineedevops/training-repo')"
                  echo 'Previously deployed application versions are removed, proceeding with the deployment of new version.'
               }
               catch (err) {
                  echo 'No previously deployed application versions were detected, proceeding with the deployment of new version.'
                  currentBuild.result = 'SUCCESS'
               }
            }
            sh "docker run -d --restart unless-stopped --name reactapp -p 4000:80 victoribatraineedevops/training-repo:1.${env.BUILD_ID}"
         }
   }
```
8.  На стадии *Deploy* перед развертыванием нового приложения необходимо убедиться, что старые версии приложения и образы, с которых они запускаются, остановлены и удалены. Для этого используются два идентичных script блока \
*try{} catch(err){}* \
которые сперва пытаются остановить и удалить контейнер и образ, и если команда проходит успешно, то выводит на экран сообщение об удалении старых версий и продолжении выполнения конвейера, а при получении ошибки от docker при выполнении команды (если к примеру это первый запуск, то на агенте не может быть образа и контейнера развернутого приложения, или же по какой-то причине будет отсутствовать один из них или оба) на экран выводится сообщение о том, что предыдущей версии приложения не найдено и продолжении выполнения конвейера, статус выполнения стадии остаётся успешным несмотря на возможные полученные ошибки, так как все возможные варианты результата выполнения команд нас будут устраивать, и конвейер продолжает развертывание приложения. Далее командой \
`sh "docker run -d --restart unless-stopped --name reactapp -p 4000:80 victoribatraineedevops/training-repo:1.${env.BUILD_ID}"` \
запускается в режиме *detached* контейнер с заданным именем *reactapp* с пробросом на его 80й порт c 4000го порта локальной машины (чтобы мы могли для данного примера зайти на [localhost:4000](localhost:4000) и проверить, как выглядит приложение) с политикой автоматического перезапуска при любых условиях (это может быть к примеру рестарт виртуальной машины или временное аварийное отключение питания сервера), что позволит повысить uptime развернутого приложения без необходимости ручного воздействия в критических ситуациях.
Замечания к реализации стадии таким образом:
*   В стадии *Deploy* время между остановкой контейнера командой `sh 'docker stop reactapp && docker rm reactapp'` и развертыванием новой версии командой `sh "docker run -d --restart unless-stopped --name reactapp -p 4000:80 victoribatraineedevops/training-repo:1.${env.BUILD_ID}"` -- это около 15 секунд downtime, когда ни старая ни новая версия приложения недоступны. Вариант развертывания приложения в кластере Kubernetes убирает этот downtime, так как pods со старой версией отключаются один за одним одновременно с подключением pods с новой версией согласно rolling update strategy.
